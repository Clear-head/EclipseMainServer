import json
import asyncio
from playwright.async_api import async_playwright, TimeoutError, Page
import re
from typing import Optional, List, Tuple
import sys, os
import datetime
import aiohttp
from dotenv import load_dotenv
import xml.etree.ElementTree as ET

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(dotenv_path="src/.env")

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from src.logger.logger_handler import get_logger
from src.domain.dto.insert_category_dto import InsertCategoryDto
from src.domain.dto.insert_category_tags_dto import InsertCategoryTagsDTO
from src.service.crawl.insert_crawled import insert_category, insert_category_tags, insert_tags
from src.service.crawl.update_crawled import update_category, update_category_tags
from src.infra.database.repository.category_repository import CategoryRepository
from src.infra.database.repository.category_tags_repository import CategoryTagsRepository

# ë¡œê±° ì´ˆê¸°í™”
logger = get_logger('crawling_naver_model')


class SeoulDistrictAPIService:
    """ì„œìš¸ì‹œ ê° êµ¬ì˜ ëª¨ë²”ìŒì‹ì  API ì„œë¹„ìŠ¤"""
    # ì„œìš¸ì‹œ 25ê°œ êµ¬ì˜ API ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘
    DISTRICT_ENDPOINTS = {
        'ê°•ë‚¨êµ¬': f'http://openAPI.gangnam.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GnModelRestaurantDesignate',
        'ê°•ë™êµ¬': f'http://openAPI.gd.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GdModelRestaurantDesignate',
        'ê°•ë¶êµ¬': f'http://openAPI.gangbuk.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GbModelRestaurantDesignate',
        'ê°•ì„œêµ¬': f'http://openAPI.gangseo.seoul.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GangseoModelRestaurantDesignate',
        'ê´€ì•…êµ¬': f'http://openAPI.gwanak.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GaModelRestaurantDesignate',
        'ê´‘ì§„êµ¬': f'http://openAPI.gwangjin.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GwangjinModelRestaurantDesignate',
        'êµ¬ë¡œêµ¬': f'http://openAPI.guro.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GuroModelRestaurantDesignate',
        'ê¸ˆì²œêµ¬': f'http://openAPI.geumcheon.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/GeumcheonModelRestaurantDesignate',
        'ë…¸ì›êµ¬': f'http://openAPI.nowon.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/NwModelRestaurantDesignate',
        'ë„ë´‰êµ¬': f'http://openAPI.dobong.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/DobongModelRestaurantDesignate',
        'ë™ëŒ€ë¬¸êµ¬': f'http://openAPI.ddm.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/DongdeamoonModelRestaurantDesignate',
        'ë™ì‘êµ¬': f'http://openAPI.dongjak.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/DjModelRestaurantDesignate',
        'ë§ˆí¬êµ¬': f'http://openAPI.mapo.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/MpModelRestaurantDesignate',
        'ì„œëŒ€ë¬¸êµ¬': f'http://openAPI.sdm.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/SeodaemunModelRestaurantDesignate',
        'ì„œì´ˆêµ¬': f'http://openAPI.seocho.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/ScModelRestaurantDesignate',
        'ì„±ë™êµ¬': f'http://openAPI.sd.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/SdModelRestaurantDesignate',
        'ì„±ë¶êµ¬': f'http://openAPI.sb.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/SbModelRestaurantDesignate',
        'ì†¡íŒŒêµ¬': f'http://openAPI.songpa.seoul.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/SpModelRestaurantDesignate',
        'ì–‘ì²œêµ¬': f'http://openAPI.yangcheon.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/YcModelRestaurantDesignate',
        'ì˜ë“±í¬êµ¬': f'http://openAPI.ydp.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/YdpModelRestaurantDesignate',
        'ìš©ì‚°êµ¬': f'http://openAPI.yongsan.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/YsModelRestaurantDesignate',
        'ì€í‰êµ¬': f'http://openAPI.ep.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/EpModelRestaurantDesignate',
        'ì¢…ë¡œêµ¬': f'http://openAPI.jongno.go.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/JongnoModelRestaurantDesignate',
        'ì¤‘êµ¬': f'http://openAPI.junggu.seoul.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/JungguModelRestaurantDesignate',
        'ì¤‘ë‘êµ¬': f'http://openAPI.jungnang.seoul.kr:8088/{os.getenv("SEOUL_DATA_KEY")}/xml/JungnangModelRestaurantDesignate',
    }
    
    def __init__(self, district_name: str):
        """
        Args:
            district_name: êµ¬ ì´ë¦„ (ì˜ˆ: 'ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬')
        """
        self.district_name = district_name
        
        if district_name not in self.DISTRICT_ENDPOINTS:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” êµ¬ì…ë‹ˆë‹¤: {district_name}. ì§€ì› ê°€ëŠ¥í•œ êµ¬: {list(self.DISTRICT_ENDPOINTS.keys())}")
        
        endpoint = self.DISTRICT_ENDPOINTS[district_name]
        self.base_url = endpoint
        
        logger.info(f"âœ“ {district_name} API ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    
    async def fetch_all_restaurants(self) -> List[dict]:
        """
        í•´ë‹¹ êµ¬ì˜ ëª¨ë²”ìŒì‹ì  APIì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë¹„ë™ê¸°)
        
        Returns:
            List[dict]: ìŒì‹ì  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì „ì²´ ê°œìˆ˜ í™•ì¸
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(f'{self.base_url}/1/1/') as response:
                    if response.status != 200:
                        logger.error(f"{self.district_name} API í˜¸ì¶œ ì˜¤ë¥˜: {response.status}")
                        return []
                    
                    # XML íŒŒì‹±
                    xml_text = await response.text()
                    root = ET.fromstring(xml_text)
                    
                    # ì „ì²´ ê°œìˆ˜ ì¶”ì¶œ
                    total_count_elem = root.find('.//list_total_count')
                    if total_count_elem is None:
                        logger.error(f"{self.district_name} API ì‘ë‹µì—ì„œ list_total_countë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        return []
                    
                    total_count = int(total_count_elem.text)
                    logger.info(f"{self.district_name} ëª¨ë²”ìŒì‹ì  ì „ì²´ ê°œìˆ˜: {total_count}ê°œ")
                
                # ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
                all_data = []
                batch_size = 1000
                
                tasks = []
                for start in range(1, total_count + 1, batch_size):
                    end = min(start + batch_size - 1, total_count)
                    url = f'{self.base_url}/{start}/{end}/'
                    tasks.append(self._fetch_batch(session, url, start, end))
                
                # ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
                batch_results = await asyncio.gather(*tasks)
                
                for batch_data in batch_results:
                    if batch_data:
                        all_data.extend(batch_data)
                
                logger.info(f"{self.district_name} ì´ {len(all_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                return all_data
            
        except Exception as e:
            logger.error(f"{self.district_name} API ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []

    async def _fetch_batch(self, session, url: str, start: int, end: int) -> List[dict]:
        """ë°°ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (XML íŒŒì‹±)"""
        try:
            logger.info(f"{self.district_name} API ë°ì´í„° ìˆ˜ì§‘ ì¤‘... {start}~{end}")
            async with session.get(url) as response:
                if response.status == 200:
                    # XML íŒŒì‹±
                    xml_text = await response.text()
                    root = ET.fromstring(xml_text)
                    
                    # row ë°ì´í„° ì¶”ì¶œ
                    rows = []
                    for row_elem in root.findall('.//row'):
                        row_data = {}
                        for child in row_elem:
                            row_data[child.tag] = child.text or ''
                        rows.append(row_data)
                    
                    return rows
                else:
                    logger.error(f"{self.district_name} ë°°ì¹˜ {start}~{end} API í˜¸ì¶œ ì˜¤ë¥˜: {response.status}")
            return []
        except Exception as e:
            logger.error(f"{self.district_name} ë°°ì¹˜ {start}~{end} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
    
    def convert_to_store_format(self, api_data: List[dict]) -> List[dict]:
        """
        API ë°ì´í„°ë¥¼ í¬ë¡¤ë§ìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜
        
        Args:
            api_data: APIì—ì„œ ê°€ì ¸ì˜¨ ì›ë³¸ ë°ì´í„°
            
        Returns:
            List[dict]: ë³€í™˜ëœ ìƒì  ë°ì´í„°
        """
        converted_data = []
        
        for idx, row in enumerate(api_data, 1):
            store = {
                'id': idx,
                'name': row.get('UPSO_NM', '').strip(),
                'address': row.get('SITE_ADDR', '').strip(),  # ì§€ë²ˆ ì£¼ì†Œ
                'road_address': row.get('SITE_ADDR_RD', '').strip(),  # ë„ë¡œëª… ì£¼ì†Œ
                'sub_category': row.get('SNT_UPTAE_NM', '').strip(),
                'admdng_nm': row.get('ADMDNG_NM', '').strip(),
                'main_edf': row.get('MAIN_EDF', '').strip(),  # ì´ê±´ ì œê±°í•´ë„ ë¨
                'original_data': row
            }
            converted_data.append(store)
        
        return converted_data


class CategoryTypeClassifier:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.api_token = os.getenv('COPILOT_API_KEY') or os.getenv('GITHUB_TOKEN')
        if self.api_token:
            self.api_endpoint = "https://api.githubcopilot.com/chat/completions"
            self.headers = {
                "Authorization": f"Bearer {self.api_token}",
                "Content-Type": "application/json",
                "Accept": "application/json"
            }
        else:
            logger.warning("GitHub API í† í°ì´ ì—†ìŠµë‹ˆë‹¤. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    
    async def classify_category_type(self, sub_category: str, max_retries: int = 5) -> int:
        """
        ì„œë¸Œ ì¹´í…Œê³ ë¦¬ë¥¼ LLMìœ¼ë¡œ ë¶„ì„í•˜ì—¬ íƒ€ì… ê²°ì •
        
        Args:
            sub_category: ì„œë¸Œ ì¹´í…Œê³ ë¦¬
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            int: 0 (ìŒì‹ì ), 1 (ì¹´í˜), 2 (ì½˜í…ì¸ ), 3 (ê¸°íƒ€)
        """
        if not self.api_token:
            logger.warning("API í† í°ì´ ì—†ì–´ ê¸°ë³¸ê°’ 3ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return 3
        
        if not sub_category or not sub_category.strip():
            logger.warning("ì„œë¸Œ ì¹´í…Œê³ ë¦¬ê°€ ë¹„ì–´ìˆì–´ ê¸°ë³¸ê°’ 3ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return 3
        
        prompt = f"""ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ìˆ«ìë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.

<ì¹´í…Œê³ ë¦¬>
{sub_category}

<ë¶„ë¥˜ ê¸°ì¤€>
- ìŒì‹ì  (í•œì‹, ì¼ì‹, ì¤‘ì‹, ì–‘ì‹, ë¶„ì‹, ì¹˜í‚¨, ê³ ê¸°, íšŒ, ë·”í˜, ìˆ ì§‘ ë“±) â†’ 0
- ì¹´í˜ (ì¹´í˜, ì»¤í”¼, ë””ì €íŠ¸, ë² ì´ì»¤ë¦¬, ë¹µì§‘, ì°¨ ë“±) â†’ 1
- ì½˜í…ì¸  (ê´€ê´‘ì§€, ë°•ë¬¼ê´€, ë¯¸ìˆ ê´€, ê³µì›, ë†€ì´ê³µì›, ì²´í—˜ê´€, ì „ì‹œê´€, í…Œë§ˆíŒŒí¬ ë“±) â†’ 2
- ë¶„ë¥˜í•˜ê¸° í˜ë“  ê²½ìš° â†’ 3

ë‹µë³€ (ìˆ«ìë§Œ):"""
        
        payload = {
            "model": "gpt-4.1",
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ìŒì‹ì (0), ì¹´í˜(1), ì½˜í…ì¸ (2), ê¸°íƒ€(3)ë¡œ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ 0, 1, 2, 3 ì¤‘ í•˜ë‚˜ì˜ ìˆ«ìë§Œ ë‹µë³€í•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.1,
            "max_tokens": 10
        }
        
        for attempt in range(1, max_retries + 1):
            try:
                timeout = aiohttp.ClientTimeout(total=30)
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    async with session.post(
                        self.api_endpoint,
                        headers=self.headers,
                        json=payload
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            category_type_str = result['choices'][0]['message']['content'].strip()
                            
                            # ìˆ«ìë§Œ ì¶”ì¶œ
                            category_type_str = re.sub(r'[^0-3]', '', category_type_str)
                            
                            if category_type_str in ['0', '1', '2', '3']:
                                category_type = int(category_type_str)
                                logger.info(f"ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì™„ë£Œ: '{sub_category}' â†’ íƒ€ì… {category_type}")
                                return category_type
                            else:
                                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì‘ë‹µ: {category_type_str}, ê¸°ë³¸ê°’ 3 ë°˜í™˜")
                                return 3
                        else:
                            logger.warning(f"âœ— ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ API í˜¸ì¶œ ì‹¤íŒ¨ ({attempt}ë²ˆì§¸ ì‹œë„) - ìƒíƒœ ì½”ë“œ: {response.status}")
                            
                            if attempt < max_retries:
                                await asyncio.sleep(2)
                            else:
                                logger.error(f"âœ— ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜({max_retries}íšŒ) ì´ˆê³¼ - ê¸°ë³¸ê°’ 3 ë°˜í™˜")
                                return 3
                
            except asyncio.TimeoutError:
                logger.warning(f"âœ— ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ API ì‹œê°„ ì´ˆê³¼ ({attempt}ë²ˆì§¸ ì‹œë„)")
                
                if attempt < max_retries:
                    await asyncio.sleep(2)
                else:
                    logger.error(f"âœ— ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜({max_retries}íšŒ) ì´ˆê³¼ - ê¸°ë³¸ê°’ 3 ë°˜í™˜")
                    return 3
                    
            except Exception as e:
                logger.error(f"âœ— ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ({attempt}ë²ˆì§¸ ì‹œë„): {e}")
                
                if attempt < max_retries:
                    await asyncio.sleep(2)
                else:
                    logger.error(f"âœ— ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜({max_retries}íšŒ) ì´ˆê³¼ - ê¸°ë³¸ê°’ 3 ë°˜í™˜")
                    return 3
        
        return 3


class GeocodingService:
    """ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì‚¬ìš©í•œ ì£¼ì†Œ -> ì¢Œí‘œ ë³€í™˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv('KAKAO_REST_API_KEY')
        
        if not self.api_key:
            logger.warning("ì¹´ì¹´ì˜¤ REST API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢Œí‘œ ë³€í™˜ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        
        self.base_url = "https://dapi.kakao.com/v2/local/search/address.json"
        self.headers = {
            "Authorization": f"KakaoAK {self.api_key}"
        }
    
    async def get_coordinates(self, address: str, max_retries: int = 5) -> Tuple[Optional[str], Optional[str]]:
        """
        ì£¼ì†Œë¥¼ ì¢Œí‘œ(ê²½ë„, ìœ„ë„)ë¡œ ë³€í™˜ (ë¹„ë™ê¸°)
        
        Args:
            address: ë³€í™˜í•  ì£¼ì†Œ
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            Tuple[Optional[str], Optional[str]]: (ê²½ë„, ìœ„ë„) ë˜ëŠ” (None, None)
        """
        if not self.api_key:
            logger.warning("API í‚¤ê°€ ì—†ì–´ ì¢Œí‘œ ë³€í™˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None, None
        
        if not address or not address.strip():
            logger.warning("ì£¼ì†Œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None, None
        
        params = {
            "query": address
        }
        
        for attempt in range(1, max_retries + 1):
            try:
                timeout = aiohttp.ClientTimeout(total=10)
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    async with session.get(
                        self.base_url,
                        headers=self.headers,
                        params=params
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            
                            if result.get('documents') and len(result['documents']) > 0:
                                doc = result['documents'][0]
                                longitude = str(doc['x'])  # ê²½ë„ (ë¬¸ìì—´)
                                latitude = str(doc['y'])   # ìœ„ë„ (ë¬¸ìì—´)
                                return longitude, latitude
                            else:
                                logger.warning(f"ì£¼ì†Œì— ëŒ€í•œ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {address}")
                                return None, None
                                
                        elif response.status == 401:
                            logger.error("ì¹´ì¹´ì˜¤ API ì¸ì¦ ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                            return None, None
                            
                        else:
                            logger.warning(f"âœ— ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨ ({attempt}ë²ˆì§¸ ì‹œë„) - ìƒíƒœ ì½”ë“œ: {response.status}")
                            
                            if attempt < max_retries:
                                await asyncio.sleep(3)
                            else:
                                logger.error(f"âœ— ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                                return None, None
                        
            except asyncio.TimeoutError:
                if attempt < max_retries:
                    await asyncio.sleep(1)
                else:
                    logger.error(f"âœ— ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                    return None, None
                    
            except Exception as e:
                logger.error(f"âœ— ì¢Œí‘œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ({attempt}ë²ˆì§¸ ì‹œë„): {e}")
                
                if attempt < max_retries:
                    await asyncio.sleep(1)
                else:
                    return None, None
        
        return None, None


class AddressParser:
    """ì£¼ì†Œ íŒŒì‹± ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    @staticmethod
    def parse_address(full_address: str) -> Tuple[str, str, str, str]:
        """
        ì „ì²´ ì£¼ì†Œë¥¼ do, si, gu, detail_addressë¡œ ë¶„ë¦¬
        
        Args:
            full_address: ì „ì²´ ì£¼ì†Œ (ì˜ˆ: "ì„œìš¸ ë§ˆí¬êµ¬ ì–‘í™”ë¡œ 144")
            
        Returns:
            Tuple[str, str, str, str]: (do, si, gu, detail_address)
        """
        if not full_address:
            return "", "", "", ""
        
        try:
            do = ""
            si = ""
            gu = ""
            detail_address = ""
            
            logger.info(f"ì›ë³¸ ì£¼ì†Œ: {full_address}")
            
            # íŠ¹ë³„ì‹œ/ê´‘ì—­ì‹œ ë§¤í•‘ (do ì—†ì´ siì—ë§Œ ë“¤ì–´ê°)
            city_mapping = {
                'ì„œìš¸': 'ì„œìš¸íŠ¹ë³„ì‹œ',
                'ë¶€ì‚°': 'ë¶€ì‚°ê´‘ì—­ì‹œ',
                'ëŒ€êµ¬': 'ëŒ€êµ¬ê´‘ì—­ì‹œ',
                'ì¸ì²œ': 'ì¸ì²œê´‘ì—­ì‹œ',
                'ê´‘ì£¼': 'ê´‘ì£¼ê´‘ì—­ì‹œ',
                'ëŒ€ì „': 'ëŒ€ì „ê´‘ì—­ì‹œ',
                'ìš¸ì‚°': 'ìš¸ì‚°ê´‘ì—­ì‹œ',
                'ì„¸ì¢…': 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'
            }
            
            # ë„ ë‹¨ìœ„ ë§¤í•‘ (ì•½ì¹­ ì²˜ë¦¬)
            do_mapping = {
                'ê²½ê¸°': 'ê²½ê¸°ë„',
                'ê°•ì›': 'ê°•ì›ë„',
                'ì¶©ë¶': 'ì¶©ì²­ë¶ë„',
                'ì¶©ë‚¨': 'ì¶©ì²­ë‚¨ë„',
                'ì „ë¶': 'ì „ë¶íŠ¹ë³„ìì¹˜ë„',
                'ì „ë‚¨': 'ì „ë¼ë‚¨ë„',
                'ê²½ë¶': 'ê²½ìƒë¶ë„',
                'ê²½ë‚¨': 'ê²½ìƒë‚¨ë„',
                'ì œì£¼': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
            }
            
            remaining = full_address
            
            # 1ë‹¨ê³„: íŠ¹ë³„ì‹œ/ê´‘ì—­ì‹œ/ë„ ì²˜ë¦¬
            for short_name, full_name in city_mapping.items():
                # "ì„œìš¸" ë˜ëŠ” "ì„œìš¸íŠ¹ë³„ì‹œ"ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
                if remaining.startswith(short_name):
                    si = full_name
                    # "ì„œìš¸" ë‹¤ìŒì´ ê³µë°±ì´ê±°ë‚˜ êµ¬ë¡œ ëë‚˜ëŠ” ë‹¨ì–´ê°€ ì˜¤ëŠ” ê²½ìš°
                    if len(remaining) > len(short_name):
                        next_char = remaining[len(short_name)]
                        if next_char == ' ':
                            remaining = remaining[len(short_name):].strip()
                        elif next_char in ['êµ¬', 'ì‹œ']:
                            remaining = remaining[len(short_name):]
                        else:
                            # "ì„œìš¸íŠ¹ë³„ì‹œ"ì²˜ëŸ¼ ë¶™ì–´ìˆëŠ” ê²½ìš°
                            if remaining.startswith(full_name):
                                remaining = remaining[len(full_name):].strip()
                            else:
                                remaining = remaining[len(short_name):]
                    else:
                        remaining = ""
                    break
            
            # ë„ ë‹¨ìœ„ ì²˜ë¦¬ (siê°€ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°)
            if not si:
                for short_name, full_name in do_mapping.items():
                    # "ê²½ê¸°" ë˜ëŠ” "ê²½ê¸°ë„"ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
                    if remaining.startswith(short_name):
                        do = full_name
                        # "ê²½ê¸°" ë‹¤ìŒì´ ê³µë°±ì´ê±°ë‚˜ ì‹œë¡œ ëë‚˜ëŠ” ë‹¨ì–´ê°€ ì˜¤ëŠ” ê²½ìš°
                        if len(remaining) > len(short_name):
                            next_char = remaining[len(short_name)]
                            if next_char == ' ':
                                remaining = remaining[len(short_name):].strip()
                            elif next_char in ['ì‹œ']:
                                remaining = remaining[len(short_name):]
                            else:
                                # "ê²½ê¸°ë„"ì²˜ëŸ¼ ë¶™ì–´ìˆëŠ” ê²½ìš°
                                if remaining.startswith(full_name):
                                    remaining = remaining[len(full_name):].strip()
                                else:
                                    remaining = remaining[len(short_name):]
                        else:
                            remaining = ""
                        break
                
                # ê¸°ì¡´ ë¡œì§: "ê²½ê¸°ë„", "ì¶©ì²­ë¶ë„" ë“± ì „ì²´ ì´ë¦„ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš°
                if not do:
                    parts = remaining.split(maxsplit=1)
                    if parts:
                        first_word = parts[0]
                        if first_word.endswith('ë„') or first_word.endswith('íŠ¹ë³„ìì¹˜ë„'):
                            do = first_word
                            remaining = parts[1] if len(parts) > 1 else ""
            
            # 2ë‹¨ê³„: doê°€ ìˆëŠ” ê²½ìš° si ì¶”ì¶œ (ì‹œ)
            if do and not si:
                # ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ê²½ìš°
                parts = remaining.split(maxsplit=1)
                if parts:
                    first_part = parts[0]
                    if first_part.endswith('ì‹œ'):
                        si = first_part
                        remaining = parts[1] if len(parts) > 1 else ""
                    else:
                        # ê³µë°± ì—†ì´ ë¶™ì–´ìˆëŠ” ê²½ìš° (ì˜ˆ: "ìˆ˜ì›ì‹œê¶Œì„ êµ¬")
                        # ì‹œë¥¼ ì°¾ì•„ì„œ ë¶„ë¦¬
                        import re
                        match = re.match(r'^([ê°€-í£]+[ì‹œ])', remaining)
                        if match:
                            si = match.group(1)
                            remaining = remaining[len(si):].strip()
            
            # 3ë‹¨ê³„: êµ¬ ì¶”ì¶œ
            if remaining:
                # ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ê²½ìš°
                parts = remaining.split(maxsplit=1)
                if parts:
                    first_part = parts[0]
                    if first_part.endswith('êµ¬'):
                        gu = first_part
                        detail_address = parts[1] if len(parts) > 1 else ""
                    else:
                        # ê³µë°± ì—†ì´ ë¶™ì–´ìˆëŠ” ê²½ìš° (ì˜ˆ: "ê¶Œì„ êµ¬ê³¡ë°˜ì •ë™")
                        import re
                        match = re.match(r'^([ê°€-í£]+[êµ¬])', remaining)
                        if match:
                            gu = match.group(1)
                            detail_address = remaining[len(gu):].strip()
                        else:
                            detail_address = remaining
            
            logger.info(f"ì£¼ì†Œ íŒŒì‹± ê²°ê³¼:")
            logger.info(f"  - do: '{do}' (NULL: {not do})")
            logger.info(f"  - si: '{si}' (NULL: {not si})")
            logger.info(f"  - gu: '{gu}' (NULL: {not gu})")
            logger.info(f"  - detail: '{detail_address}'")
            
            return do, si, gu, detail_address
            
        except Exception as e:
            logger.error(f"ì£¼ì†Œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return "", "", "", full_address


class NaverMapDistrictCrawler:
    """ì„œìš¸ì‹œ ê° êµ¬ API ë°ì´í„° í¬ë¡¤ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, district_name: str, headless: bool = False):
        """
        Args:
            district_name: í¬ë¡¤ë§í•  êµ¬ ì´ë¦„ (ì˜ˆ: 'ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬')
            headless: í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        """
        self.district_name = district_name
        self.headless = headless
        self.naver_map_url = "https://map.naver.com/v5/search"
        self.geocoding_service = GeocodingService()
        self.category_classifier = CategoryTypeClassifier()
        
        logger.info(f"âœ“ {district_name} í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def _save_store_data(self, idx: int, total: int, store_data: Tuple, store_name: str, store_id: int, api_sub_category: str):
        """
        í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ DBì— ì €ì¥í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
        
        Args:
            idx: í˜„ì¬ ì¸ë±ìŠ¤
            total: ì „ì²´ ê°œìˆ˜
            store_data: í¬ë¡¤ë§í•œ ìƒì  ë°ì´í„°
            store_name: ìƒì ëª…
            store_id: ìƒì  ID
            api_sub_category: APIì—ì„œ ê°€ì ¸ì˜¨ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ (ë³´ì¡°ìš©)
            
        Returns:
            Tuple[bool, str]: (ì„±ê³µ ì—¬ë¶€, ë¡œê·¸ ë©”ì‹œì§€)
        """
        try:
            name, full_address, phone, business_hours, image, naver_sub_category, tag_reviews = store_data
            
            # ì£¼ì†Œ íŒŒì‹±
            do, si, gu, detail_address = AddressParser.parse_address(full_address)
            
            # â­ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ê²°ì •: ë„¤ì´ë²„ ì§€ë„ ìš°ì„ 
            # 1ìˆœìœ„: ë„¤ì´ë²„ ì§€ë„ ì„œë¸Œ ì¹´í…Œê³ ë¦¬
            # 2ìˆœìœ„: API ì„œë¸Œ ì¹´í…Œê³ ë¦¬
            final_sub_category = naver_sub_category or api_sub_category
            
            logger.info(f"[{self.district_name} ì €ì¥ {idx+1}/{total}] ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ê²°ì •:")
            logger.info(f"  - ë„¤ì´ë²„ ì„œë¸Œ ì¹´í…Œê³ ë¦¬: {naver_sub_category}")
            logger.info(f"  - API ì„œë¸Œ ì¹´í…Œê³ ë¦¬: {api_sub_category}")
            logger.info(f"  - ìµœì¢… ì„ íƒ (ì €ì¥ & íƒ€ì… ë¶„ë¥˜): {final_sub_category}")
            
            # ì¢Œí‘œ ë³€í™˜ê³¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
            # â­ ë„¤ì´ë²„ ì§€ë„ì˜ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ë¡œ íƒ€ì… ë¶„ë¥˜
            (longitude, latitude), category_type = await asyncio.gather(
                self.geocoding_service.get_coordinates(full_address),
                self.category_classifier.classify_category_type(final_sub_category)
            )
            
            # DTO ìƒì„±
            category_dto = InsertCategoryDto(
                name=name,
                do=do,
                si=si,
                gu=gu,
                detail_address=detail_address,
                sub_category=final_sub_category,  # ë„¤ì´ë²„ ìš°ì„ 
                business_hour=business_hours or "",
                phone=phone.replace('-', '') if phone else "",
                type=category_type,  # ë„¤ì´ë²„ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜ëœ íƒ€ì…
                image=image or "",
                latitude=latitude or "",
                longitude=longitude or ""
            )
            
            # category ì €ì¥ (ì¤‘ë³µ ì²´í¬ í¬í•¨)
            # 1. ë¨¼ì € DBì—ì„œ ì¤‘ë³µ ì²´í¬ (name, type, detail_addressë¡œ ì¡°íšŒ)
            category_repository = CategoryRepository()
            existing_categories = await category_repository.select_by(
                name=name,
                type=category_type,
                detail_address=detail_address
            )
            
            category_id = None
            
            # 2. ì¤‘ë³µ ë°ì´í„°ê°€ ìˆìœ¼ë©´ update, ì—†ìœ¼ë©´ insert
            if len(existing_categories) == 1:
                # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                logger.info(f"[{self.district_name} ì €ì¥ {idx+1}/{total}] ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ë°œê²¬ - ì—…ë°ì´íŠ¸ ëª¨ë“œ: {name}")
                category_id = await update_category(category_dto)
            elif len(existing_categories) == 0:
                # ìƒˆë¡œìš´ ë°ì´í„° ì‚½ì…
                logger.info(f"[{self.district_name} ì €ì¥ {idx+1}/{total}] ì‹ ê·œ ì¹´í…Œê³ ë¦¬ - ì‚½ì… ëª¨ë“œ: {name}")
                category_id = await insert_category(category_dto)
            else:
                # ì¤‘ë³µì´ 2ê°œ ì´ìƒì¸ ê²½ìš° (ë°ì´í„° ë¬´ê²°ì„± ë¬¸ì œ)
                logger.error(f"[{self.district_name} ì €ì¥ {idx+1}/{total}] ì¤‘ë³µ ì¹´í…Œê³ ë¦¬ê°€ {len(existing_categories)}ê°œ ë°œê²¬ë¨: {name}")
                raise Exception(f"ì¤‘ë³µ ì¹´í…Œê³ ë¦¬ ë°ì´í„° ë¬´ê²°ì„± ì˜¤ë¥˜: {name}")
            
            if category_id:
                # íƒœê·¸ ë¦¬ë·° ì €ì¥ (ì¤‘ë³µ ì²´í¬ í¬í•¨)
                tag_success_count = 0
                for tag_name, tag_count in tag_reviews:
                    try:
                        # tags í…Œì´ë¸”ì— ì €ì¥ ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
                        tag_id = await insert_tags(tag_name, category_type)
                        
                        if tag_id:
                            # category_tags DTO ìƒì„±
                            category_tags_dto = InsertCategoryTagsDTO(
                                tag_id=tag_id,
                                category_id=category_id,
                                count=tag_count
                            )
                            
                            # 3. category_tagsë„ ì¤‘ë³µ ì²´í¬
                            category_tags_repository = CategoryTagsRepository()
                            existing_tags = await category_tags_repository.select_by(
                                tag_id=tag_id,
                                category_id=category_id
                            )
                            
                            # ì¤‘ë³µì´ë©´ update, ì•„ë‹ˆë©´ insert
                            if len(existing_tags) == 1:
                                if await update_category_tags(category_tags_dto):
                                    tag_success_count += 1
                            elif len(existing_tags) == 0:
                                if await insert_category_tags(category_tags_dto):
                                    tag_success_count += 1
                            else:
                                logger.error(f"ì¤‘ë³µ íƒœê·¸ê°€ {len(existing_tags)}ê°œ ë°œê²¬ë¨")
                                
                    except Exception as tag_error:
                        logger.error(f"íƒœê·¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {tag_name} - {tag_error}")
                        continue
                
                type_names = {0: 'ìŒì‹ì ', 1: 'ì¹´í˜', 2: 'ì½˜í…ì¸ ', 3: 'ê¸°íƒ€'}
                success_msg = (
                    f"âœ“ [{self.district_name} ì €ì¥ {idx}/{total}] ID {store_id} '{name}' ì™„ë£Œ\n"
                    f"  - ì €ì¥ëœ ì„œë¸Œ ì¹´í…Œê³ ë¦¬: {final_sub_category}\n"
                    f"  - íƒ€ì…: {type_names.get(category_type, 'ê¸°íƒ€')} ({category_type})\n"
                    f"  - íƒœê·¸ ë¦¬ë·°: {tag_success_count}/{len(tag_reviews)}ê°œ ì €ì¥"
                )
                logger.info(success_msg)
                return True, success_msg
            else:
                error_msg = f"âœ— [{self.district_name} ì €ì¥ {idx+1}/{total}] ID {store_id} '{name}' DB ì €ì¥ ì‹¤íŒ¨"
                logger.error(error_msg)
                return False, error_msg
                
        except Exception as db_error:
            error_msg = f"âœ— [{self.district_name} ì €ì¥ {idx+1}/{total}] ID {store_id} '{store_name}' DB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {db_error}"
            logger.error(error_msg)
            import traceback
            logger.error(traceback.format_exc())
            return False, error_msg
    
    async def crawl_district_api(self, delay: int = 20):
        """
        í•´ë‹¹ êµ¬ì˜ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ í¬ë¡¤ë§
        í¬ë¡¤ë§ê³¼ ì €ì¥ì„ ë¶„ë¦¬í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
        
        Args:
            delay: í¬ë¡¤ë§ ê°„ ë”œë ˆì´ (ì´ˆ)
        """
        # í•´ë‹¹ êµ¬ì˜ APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë¹„ë™ê¸°)
        api_service = SeoulDistrictAPIService(self.district_name)
        api_data = await api_service.fetch_all_restaurants()
        
        if not api_data:
            logger.warning(f"{self.district_name} APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í¬ë¡¤ë§ìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜
        stores = api_service.convert_to_store_format(api_data)
        
        total = len(stores)
        success_count = 0
        fail_count = 0
        
        logger.info(f"ì´ {total}ê°œ {self.district_name} ëª¨ë²”ìŒì‹ì  í¬ë¡¤ë§ ì‹œì‘")
        logger.info("=" * 60)
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(
                headless=self.headless,
                args=['--enable-features=ClipboardAPI']  # í´ë¦½ë³´ë“œ API í™œì„±í™”
            )
            
            # ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹œ í´ë¦½ë³´ë“œ ê¶Œí•œ ë¶€ì—¬
            context = await browser.new_context(
                permissions=['clipboard-read', 'clipboard-write']
            )
            page = await context.new_page()
            
            try:
                # ì €ì¥ íƒœìŠ¤í¬ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
                save_tasks = []
                
                for idx, store in enumerate(stores, 1):
                    store_id = store['id']
                    store_name = store['name']
                    store_address = store['address']  # ì§€ë²ˆ ì£¼ì†Œ
                    road_address = store['road_address']  # ë„ë¡œëª… ì£¼ì†Œ (SITE_ADDR_RD)
                    api_sub_category = store['sub_category']  # API ì„œë¸Œ ì¹´í…Œê³ ë¦¬
                    admdng_nm = store['admdng_nm']
                    
                    logger.info(f"[{self.district_name} í¬ë¡¤ë§ {idx}/{total}] ID {store_id}: '{store_name}' (í–‰ì •ë™: {admdng_nm}) í¬ë¡¤ë§ ì§„í–‰ ì¤‘...")
                    logger.info(f"  - API ì„œë¸Œ ì¹´í…Œê³ ë¦¬: {api_sub_category}")
                    logger.info(f"  - ì§€ë²ˆ ì£¼ì†Œ: {store_address}")
                    logger.info(f"  - ë„ë¡œëª… ì£¼ì†Œ: {road_address}")
                    
                    # ë„¤ì´ë²„ ì§€ë„ì—ì„œ ê²€ìƒ‰ (ë„ë¡œëª… ì£¼ì†Œ ì „ë‹¬)
                    store_data = await self._search_and_extract(page, store_name, store_address, road_address)
                    
                    if store_data:
                        # store_dataì—ì„œ ë„¤ì´ë²„ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                        naver_sub_category = store_data[5]  # (name, address, phone, hours, image, sub_category, tags)
                        logger.info(f"  - ë„¤ì´ë²„ ì„œë¸Œ ì¹´í…Œê³ ë¦¬: {naver_sub_category}")
                        logger.info(f"âœ“ [{self.district_name} í¬ë¡¤ë§ {idx}/{total}] ID {store_id} '{store_name}' í¬ë¡¤ë§ ì™„ë£Œ")
                        
                        # ì €ì¥ íƒœìŠ¤í¬ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
                        save_task = asyncio.create_task(
                            self._save_store_data(idx, total, store_data, store_name, store_id, api_sub_category)
                        )
                        save_tasks.append(save_task)
                        
                        # ë§ˆì§€ë§‰ ìƒì ì´ ì•„ë‹ˆë©´ ë”œë ˆì´
                        if idx < total:
                            logger.info(f"[{self.district_name} ëŒ€ê¸°] {delay}ì´ˆ ëŒ€ê¸° ì¤‘... (ì €ì¥ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰)")
                            await asyncio.sleep(delay)
                    else:
                        fail_count += 1
                        logger.error(f"âœ— [{self.district_name} í¬ë¡¤ë§ {idx}/{total}] ID {store_id} '{store_name}' í¬ë¡¤ë§ ì‹¤íŒ¨")
                        
                        # ì‹¤íŒ¨í•´ë„ ë”œë ˆì´
                        if idx < total:
                            logger.info(f"[{self.district_name} ëŒ€ê¸°] {delay}ì´ˆ ëŒ€ê¸° ì¤‘...")
                            await asyncio.sleep(delay)
                
                # ëª¨ë“  í¬ë¡¤ë§ì´ ëë‚œ í›„ ì €ì¥ íƒœìŠ¤í¬ë“¤ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                logger.info("=" * 60)
                logger.info(f"{self.district_name} ëª¨ë“  í¬ë¡¤ë§ ì™„ë£Œ! ì €ì¥ ì‘ì—… ì™„ë£Œ ëŒ€ê¸° ì¤‘... ({len(save_tasks)}ê°œ)")
                logger.info("=" * 60)
                
                if save_tasks:
                    save_results = await asyncio.gather(*save_tasks, return_exceptions=True)
                    
                    # ì €ì¥ ê²°ê³¼ ì§‘ê³„
                    for result in save_results:
                        if isinstance(result, Exception):
                            fail_count += 1
                        elif isinstance(result, tuple):
                            success, msg = result
                            if success:
                                success_count += 1
                            else:
                                fail_count += 1
                
                logger.info("=" * 60)
                logger.info(f"{self.district_name} ì „ì²´ ì‘ì—… ì™„ë£Œ: ì„±ê³µ {success_count}/{total}, ì‹¤íŒ¨ {fail_count}/{total}")
                logger.info("=" * 60)
                
            except Exception as e:
                logger.error(f"{self.district_name} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                logger.error(traceback.format_exc())
            finally:
                await context.close()
                await browser.close()

    async def _search_and_extract(self, page: Page, store_name: str, store_address: str, road_address: str = ""):
        """ë„¤ì´ë²„ ì§€ë„ì—ì„œ ê²€ìƒ‰ ë° ì •ë³´ ì¶”ì¶œ (ë„ë¡œëª… ì£¼ì†Œ ìš°ì„ )"""
        
        # ë„ë¡œëª… ì£¼ì†Œê°€ ìˆëŠ” ê²½ìš° ìš°ì„  ê²€ìƒ‰
        if road_address and road_address.strip():
            # 1ì°¨ ì‹œë„: ë„ë¡œëª… ì£¼ì†Œ(~ë¡œ/ê¸¸ê¹Œì§€) + ë§¤ì¥ëª…
            road_parts = road_address.split()
            if len(road_parts) >= 2:
                # ~ë¡œ, ~ê¸¸ê¹Œì§€ë§Œ ì¶”ì¶œ
                road_keyword = self._extract_road_name(road_parts)
                if road_keyword:
                    first_keyword = f"{road_keyword} {store_name}"
                    logger.info(f"ğŸ” 1ì°¨ ê²€ìƒ‰: {first_keyword}")
                    result = await self._search_single(page, first_keyword)
                    if result:
                        return result
                    
                    await asyncio.sleep(4)
                    logger.warning(f"âœ— 1ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨")
            
            # 2ì°¨ ì‹œë„: ë„ë¡œëª… ì „ì²´ ì£¼ì†Œ + ë§¤ì¥ëª…
            second_keyword = f"{road_address} {store_name}"
            logger.info(f"ğŸ” 2ì°¨ ê²€ìƒ‰: {second_keyword}")
            result = await self._search_single(page, second_keyword)
            if result:
                return result
            
            await asyncio.sleep(4)
            logger.warning(f"âœ— 2ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨")
        
        # 3ì°¨ ì‹œë„: ì§€ë²ˆì£¼ì†Œ(~ë™ê¹Œì§€) + ê°€ê²Œëª…
        address_parts = store_address.split()
        if len(address_parts) >= 3:
            third_keyword = f"{self._extract_search_address(address_parts)} {store_name}"
        else:
            third_keyword = f"{store_address} {store_name}"
        
        logger.info(f"ğŸ” 3ì°¨ ê²€ìƒ‰: {third_keyword}")
        result = await self._search_single(page, third_keyword)
        if result:
            return result
        
        await asyncio.sleep(4)
        logger.warning(f"âœ— 3ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨")
        
        # 4ì°¨ ì‹œë„: ë§¤ì¥ëª…ë§Œ
        logger.info(f"ğŸ” 4ì°¨ ê²€ìƒ‰: {store_name}")
        result = await self._search_single(page, store_name)
        if result:
            return result
        
        await asyncio.sleep(4)
        logger.warning(f"âœ— 4ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨")
        
        # 5ì°¨ ì‹œë„: ì§€ë²ˆ ì£¼ì†Œë§Œ
        logger.info(f"ğŸ” 5ì°¨ ê²€ìƒ‰: {store_address}")
        result = await self._search_single(page, store_address)
        if result:
            return result
        
        await asyncio.sleep(4)
        logger.warning(f"âœ— 5ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨")
        
        # 6ì°¨ ì‹œë„: ì§€ë²ˆ ì „ì²´ ì£¼ì†Œ + ë§¤ì¥ëª…
        sixth_keyword = f"{store_address} {store_name}"
        logger.info(f"ğŸ” 6ì°¨ ê²€ìƒ‰: {sixth_keyword}")
        result = await self._search_single(page, sixth_keyword)
        if result:
            return result
        
        logger.error(f"âœ— ëª¨ë“  ê²€ìƒ‰ ì‹œë„ ì‹¤íŒ¨: {store_name}")
        return None

    def _extract_road_name(self, road_parts: List[str]) -> str:
        """ë„ë¡œëª… ì£¼ì†Œì—ì„œ ~ë¡œ, ~ê¸¸ê¹Œì§€ë§Œ ì¶”ì¶œ"""
        if not road_parts:
            return ""
        
        result_parts = []
        
        for part in road_parts:
            result_parts.append(part)
            
            # ~ë¡œ, ~ê¸¸ì´ ë‚˜ì˜¤ë©´ ë°”ë¡œ ì¢…ë£Œ
            if part.endswith('ë¡œ') or part.endswith('ê¸¸'):
                break
            
            # ì•ˆì „ì¥ì¹˜: ìµœëŒ€ 4ê°œ ìš”ì†Œê¹Œì§€
            if len(result_parts) >= 4:
                break
        
        return " ".join(result_parts)
    
    def _extract_search_address(self, address_parts: List[str]) -> str:
        """ì£¼ì†Œì—ì„œ ê²€ìƒ‰ì— ì í•©í•œ ë¶€ë¶„ ì¶”ì¶œ (ì§€ë²ˆ ì£¼ì†Œ ~ë™ê¹Œì§€)"""
        if not address_parts:
            return ""
        
        result_parts = []
        
        for part in address_parts:
            result_parts.append(part)
            
            # ì/ë©´/ë™ì´ ë‚˜ì˜¤ë©´ ë°”ë¡œ ì¢…ë£Œ
            if part.endswith('ì') or part.endswith('ë©´') or part.endswith('ë™') or part.endswith('ë¦¬'):
                break
            
            # ë„ë¡œëª…(~ë¡œ, ~ê¸¸)ì´ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
            elif part.endswith('ë¡œ') or part.endswith('ê¸¸'):
                break
            
            # ì•ˆì „ì¥ì¹˜: ìµœëŒ€ 4ê°œ ìš”ì†Œê¹Œì§€
            if len(result_parts) >= 4:
                break
        
        return " ".join(result_parts)
    
    async def _search_single(self, page: Page, keyword: str):
        """ë‹¨ì¼ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰"""
        try:
            # ë„¤ì´ë²„ ì§€ë„ ì´ë™
            await page.goto(self.naver_map_url)
            
            # ê²€ìƒ‰
            search_input_selector = '.input_search'
            await page.wait_for_selector(search_input_selector)
            await asyncio.sleep(1)
            
            await page.fill(search_input_selector, '')
            await asyncio.sleep(0.5)
            
            await page.fill(search_input_selector, keyword)
            await page.press(search_input_selector, 'Enter')
            
            # entry iframe ëŒ€ê¸°
            await page.wait_for_selector('iframe#entryIframe', timeout=10000)
            entry_frame = page.frame_locator('iframe#entryIframe')
            await asyncio.sleep(3)
            
            # ì •ë³´ ì¶”ì¶œ
            extractor = StoreDetailExtractor(entry_frame, page)
            return await extractor.extract_all_details()
            
        except TimeoutError:
            logger.error(f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        except Exception as e:
            logger.error(f"'{keyword}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None


class StoreDetailExtractor:
    """ìƒì  ìƒì„¸ ì •ë³´ ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self, frame, page: Page):
        self.frame = frame
        self.page = page
        
        self.api_token = os.getenv('COPILOT_API_KEY') or os.getenv('GITHUB_TOKEN')
        if self.api_token:
            self.api_endpoint = "https://api.githubcopilot.com/chat/completions"
            self.headers = {
                "Authorization": f"Bearer {self.api_token}",
                "Content-Type": "application/json",
                "Accept": "application/json"
            }
        else:
            logger.warning("GitHub API í† í°ì´ ì—†ìŠµë‹ˆë‹¤. ì˜ì—…ì‹œê°„ ì •ë¦¬ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    
    def _clean_utf8_string(self, text: str) -> str:
        """4ë°”ì´íŠ¸ UTF-8 ë¬¸ì ì œê±° (ì´ëª¨ì§€ ë“±)"""
        if not text:
            return text
        cleaned = text.encode('utf-8', 'ignore').decode('utf-8', 'ignore')
        cleaned = cleaned.replace('\n', ' ')
        return cleaned
    
    async def extract_all_details(self) -> Optional[Tuple]:
        """
        ëª¨ë“  ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        
        Returns:
            Tuple: (name, full_address, phone, business_hours, image, sub_category, tag_reviews)
        """
        try:
            name = await self._extract_title()
            full_address = await self._extract_address()
            phone = await self._extract_phone()
            business_hours = await self._extract_business_hours()
            image = await self._extract_image()
            sub_category = await self._extract_sub_category()
            tag_reviews = await self._extract_tag_reviews()
            
            logger.info(f"ìƒì  ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: {name}")
            logger.info(f"  - ì£¼ì†Œ: {full_address}")
            logger.info(f"  - ì„œë¸Œ ì¹´í…Œê³ ë¦¬: {sub_category}")
            logger.info(f"  - íƒœê·¸ ë¦¬ë·°: {len(tag_reviews)}ê°œ")
            
            return (name, full_address, phone, business_hours, image, sub_category, tag_reviews)
            
        except Exception as e:
            logger.error(f"ìƒì  ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def _extract_title(self) -> str:
        """ë§¤ì¥ëª… ì¶”ì¶œ"""
        try:
            name_locator = self.frame.locator('span.GHAhO')
            return await name_locator.inner_text(timeout=5000)
        except:
            return ""
    
    async def _extract_address(self) -> str:
        """ì£¼ì†Œ ì¶”ì¶œ (ì§€ë²ˆ ì£¼ì†Œ)"""
        try:
            # ì£¼ì†Œ ë²„íŠ¼ í´ë¦­
            address_section = self.frame.locator('div.place_section_content > div > div.O8qbU.tQY7D')
            await address_section.scroll_into_view_if_needed()
            await asyncio.sleep(1)
            
            address_button = self.frame.locator('div.place_section_content > div > div.O8qbU.tQY7D > div > a')
            await address_button.wait_for(state='visible', timeout=5000)
            await asyncio.sleep(0.5)
            
            await address_button.click()
            await asyncio.sleep(2)
            
            # ì§€ë²ˆ ì£¼ì†Œ ì¶”ì¶œ
            jibun_address_div = self.frame.locator('div.place_section_content > div > div.O8qbU.tQY7D > div > div.Y31Sf > div:nth-child(2)')
            await jibun_address_div.wait_for(state='visible', timeout=5000)
            
            jibun_address = await jibun_address_div.evaluate('''
                (element) => {
                    let text = '';
                    for (let node of element.childNodes) {
                        if (node.nodeType === Node.TEXT_NODE) {
                            text += node.textContent;
                        }
                    }
                    return text.trim();
                }
            ''')
            
            # ë²„íŠ¼ ë‹«ê¸°
            try:
                await address_button.click()
                await asyncio.sleep(0.5)
            except:
                pass
            
            return jibun_address
        except:
            # ê¸°ë³¸ ì£¼ì†Œ ì‹œë„
            try:
                fallback_locator = self.frame.locator('div.place_section_content > div > div.O8qbU.tQY7D > div > a > span.LDgIH')
                return await fallback_locator.inner_text(timeout=3000)
            except:
                return ""
    
    async def _extract_phone(self) -> str:
        """ì „í™”ë²ˆí˜¸ ì¶”ì¶œ (í´ë¦½ë³´ë“œ ë³µì‚¬ ë°©ì‹ í¬í•¨)"""
        try:
            # 1ì°¨ ì‹œë„: ê¸°ë³¸ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ
            phone_locator = self.frame.locator('div.O8qbU.nbXkr > div > span.xlx7Q')
            phone = await phone_locator.inner_text(timeout=5000)
            if phone and phone.strip():
                logger.info(f"ì „í™”ë²ˆí˜¸ ì¶”ì¶œ ì„±ê³µ: {phone}")
                return phone
        except TimeoutError:
            logger.warning(f"ê¸°ë³¸ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ ì‹¤íŒ¨ - ëŒ€ì²´ ë°©ë²• ì‹œë„")
        except Exception as e:
            logger.warning(f"ê¸°ë³¸ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ ì˜¤ë¥˜: {e} - ëŒ€ì²´ ë°©ë²• ì‹œë„")
        
        # 2ì°¨ ì‹œë„: a.BfF3H í´ë¦­ í›„ a.place_bluelinkì—ì„œ í´ë¦½ë³´ë“œ ë³µì‚¬
        try:
            logger.info("a.BfF3H ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
            bf_button = self.frame.locator('a.BfF3H')
            
            if await bf_button.count() > 0:
                logger.info("a.BfF3H ë²„íŠ¼ í´ë¦­ ì¤‘...")
                await bf_button.first.click(timeout=3000)
                await asyncio.sleep(1)
                
                # a.place_bluelink í´ë¦­í•˜ì—¬ í´ë¦½ë³´ë“œì— ë³µì‚¬
                logger.info("a.place_bluelink ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
                bluelink_button = self.frame.locator('a.place_bluelink')
                
                if await bluelink_button.count() > 0:
                    logger.info("a.place_bluelink ë²„íŠ¼ í´ë¦­ ì¤‘ (í´ë¦½ë³´ë“œ ë³µì‚¬)...")
                    
                    # í´ë¦½ë³´ë“œ ê¶Œí•œ í—ˆìš© ë° í´ë¦­
                    await bluelink_button.first.click(timeout=3000)
                    await asyncio.sleep(0.5)
                    
                    # í´ë¦½ë³´ë“œì—ì„œ ì „í™”ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
                    try:
                        # Playwrightì˜ page ê°ì²´ë¥¼ í†µí•´ í´ë¦½ë³´ë“œ ì ‘ê·¼
                        clipboard_text = await self.page.evaluate('navigator.clipboard.readText()')
                        
                        if clipboard_text and clipboard_text.strip():
                            logger.info(f"í´ë¦½ë³´ë“œì—ì„œ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ ì„±ê³µ: {clipboard_text}")
                            return clipboard_text.strip()
                        else:
                            logger.warning("í´ë¦½ë³´ë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                    except Exception as clipboard_error:
                        logger.error(f"í´ë¦½ë³´ë“œ ì½ê¸° ì‹¤íŒ¨: {clipboard_error}")
                else:
                    logger.warning("a.place_bluelink ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            else:
                logger.warning("a.BfF3H ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"ëŒ€ì²´ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        logger.warning("ì „í™”ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ë¹ˆ ê°’ ë°˜í™˜")
        return ""
    
    async def _extract_sub_category(self) -> str:
        """ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        try:
            sub_category_locator = self.frame.locator('#_title > div > span.lnJFt')
            return await sub_category_locator.inner_text(timeout=5000)
        except:
            return ""
    
    async def _extract_business_hours(self) -> str:
        """ì˜ì—…ì‹œê°„ ì¶”ì¶œ ë° LLMìœ¼ë¡œ ì •ë¦¬"""
        try:
            business_hours_button = self.frame.locator('div.O8qbU.pSavy a').first
            
            if await business_hours_button.is_visible(timeout=5000):
                await business_hours_button.scroll_into_view_if_needed()
                await asyncio.sleep(1)
                
                await business_hours_button.click()
                await asyncio.sleep(1)
                
                business_hours_locators = self.frame.locator('div.O8qbU.pSavy div.w9QyJ')
                hours_list = await business_hours_locators.all_inner_texts()
                
                if hours_list:
                    raw_hours = "\n".join(hours_list)
                    cleaned_hours = await self._clean_business_hours_with_llm(raw_hours)
                    return cleaned_hours
            return ""
        except:
            return ""
    
    async def _clean_business_hours_with_llm(self, raw_hours: str, max_retries: int = 10) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì˜ì—…ì‹œê°„ ì •ë¦¬ (ë¹„ë™ê¸°)"""
        if not self.api_token or not raw_hours:
            return raw_hours
        
        prompt = f"""ë‹¤ìŒì€ ìƒì ì˜ ì˜ì—…ì‹œê°„ ì •ë³´ì…ë‹ˆë‹¤. ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì„ ì œê±°í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

<ì›ë³¸ ì˜ì—…ì‹œê°„>
{raw_hours}

<ì§€ì¹¨>
1. ì¤‘ë³µë˜ëŠ” ì •ë³´ëŠ” í•˜ë‚˜ë¡œ í†µí•©í•˜ì„¸ìš”
2. ìš”ì¼ë³„ ì˜ì—…ì‹œê°„ì„ ëª…í™•í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”
3. ë¸Œë ˆì´í¬íƒ€ì„, ë¼ìŠ¤íŠ¸ì˜¤ë” ë“± ì¤‘ìš”í•œ ì •ë³´ëŠ” ìœ ì§€í•˜ì„¸ìš”
4. ë¶ˆí•„ìš”í•œ ë°˜ë³µì€ ì œê±°í•˜ì„¸ìš”
5. ê°„ê²°í•˜ê³  ì½ê¸° ì‰½ê²Œ ì •ë¦¬í•˜ì„¸ìš”
6. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì •ë¦¬ëœ ì˜ì—…ì‹œê°„ë§Œ ë‹µë³€í•˜ì„¸ìš”

ë‹µë³€ (ì •ë¦¬ëœ ì˜ì—…ì‹œê°„ë§Œ):"""
        
        payload = {
            "model": "gpt-4.1",
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìƒì  ì˜ì—…ì‹œê°„ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 500
        }
        
        for attempt in range(1, max_retries + 1):
            try:
                timeout = aiohttp.ClientTimeout(total=30)
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    async with session.post(
                        self.api_endpoint,
                        headers=self.headers,
                        json=payload
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            return result['choices'][0]['message']['content'].strip()
                        else:
                            if attempt < max_retries:
                                await asyncio.sleep(2)
                            else:
                                return raw_hours
            except:
                if attempt < max_retries:
                    await asyncio.sleep(2)
                else:
                    return raw_hours
        
        return raw_hours
    
    async def _extract_image(self) -> str:
        """ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        try:
            first_selector = 'div[role="main"] > div > div > a > img'
            first_image = self.frame.locator(first_selector).first
            
            if await first_image.count() > 0:
                src = await first_image.get_attribute('src', timeout=5000)
                if src:
                    return src
            
            second_selector = 'div[role="main"] > div > div > div > div > a > img'
            second_image = self.frame.locator(second_selector).first
            
            if await second_image.count() > 0:
                src = await second_image.get_attribute('src', timeout=5000)
                if src:
                    return src
            
            return ""
        except:
            return ""
    
    async def _extract_tag_reviews(self) -> List[Tuple[str, int]]:
        """íƒœê·¸ ë¦¬ë·° ì¶”ì¶œ"""
        tag_reviews = []
        
        try:
            # ë¦¬ë·° íƒ­ í´ë¦­
            await self.frame.locator('a[href*="review"][role="tab"]').click()
            await asyncio.sleep(2)
            
            # íƒœê·¸ ë¦¬ë·° ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­
            while True:
                try:
                    show_more_button = self.frame.locator('div.mrSZf > div > a')
                    await show_more_button.click(timeout=3000)
                    await asyncio.sleep(1)
                except TimeoutError:
                    break
            
            # íƒœê·¸ ë¦¬ë·° ì¶”ì¶œ
            opinion_elements = await self.frame.locator('div.mrSZf > ul > li').all()
            
            for opinion_element in opinion_elements:
                try:
                    review_tag = await opinion_element.locator('span.t3JSf').inner_text(timeout=3000)
                    rating = await opinion_element.locator('span.CUoLy').inner_text(timeout=3000)
                    cleaned_rating = int(re.sub(r'ì´ í‚¤ì›Œë“œë¥¼ ì„ íƒí•œ ì¸ì›\n', '', rating).replace(',', ''))
                    tag_reviews.append((review_tag, cleaned_rating))
                except:
                    continue
            
            logger.info(f"íƒœê·¸ ë¦¬ë·° {len(tag_reviews)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"íƒœê·¸ ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return tag_reviews


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # ========================================
    # ğŸ”§ ì—¬ê¸°ì„œ í¬ë¡¤ë§í•  êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”!
    # ========================================
    
    # ë‹¨ì¼ êµ¬ í¬ë¡¤ë§ ì˜ˆì‹œ:
    # district_name = 'ê°•ë‚¨êµ¬'
    # district_name = 'ì„œì´ˆêµ¬'
    # district_name = 'ë§ˆí¬êµ¬'
    
    # ë˜ëŠ” ì—¬ëŸ¬ êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í¬ë¡¤ë§:
    districts_to_crawl = [
        'ê°•ë‚¨êµ¬',
        'ê°•ë™êµ¬',
        'ê°•ë¶êµ¬',
        'ê°•ì„œêµ¬',
        'ê´€ì•…êµ¬',
        'ê´‘ì§„êµ¬',
        'êµ¬ë¡œêµ¬',
        'ê¸ˆì²œêµ¬',
        'ë…¸ì›êµ¬',
        'ë„ë´‰êµ¬',
        'ë™ëŒ€ë¬¸êµ¬',
        'ë™ì‘êµ¬',
        'ë§ˆí¬êµ¬',
        'ì„œëŒ€ë¬¸êµ¬',
        'ì„œì´ˆêµ¬',
        'ì„±ë™êµ¬',
        'ì„±ë¶êµ¬',
        'ì†¡íŒŒêµ¬',
        'ì–‘ì²œêµ¬',
        'ì˜ë“±í¬êµ¬',
        'ìš©ì‚°êµ¬',
        'ì€í‰êµ¬',
        'ì¢…ë¡œêµ¬',
        'ì¤‘êµ¬',
        'ì¤‘ë‘êµ¬'
    ]
    
    # ========================================
    # í¬ë¡¤ë§ ì„¤ì •
    # ========================================
    headless_mode = False  # Trueë¡œ ì„¤ì •í•˜ë©´ ë¸Œë¼ìš°ì €ê°€ ë³´ì´ì§€ ì•ŠìŒ
    delay_seconds = 30     # í¬ë¡¤ë§ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    
    # ========================================
    # í¬ë¡¤ë§ ì‹¤í–‰
    # ========================================
    
    logger.info("=" * 80)
    logger.info(f"í¬ë¡¤ë§ ì‹œì‘ - ì´ {len(districts_to_crawl)}ê°œ êµ¬")
    logger.info(f"ëŒ€ìƒ êµ¬: {', '.join(districts_to_crawl)}")
    logger.info("=" * 80)
    
    for idx, district_name in enumerate(districts_to_crawl, 1):
        try:
            logger.info("")
            logger.info("=" * 80)
            logger.info(f"[{idx}/{len(districts_to_crawl)}] {district_name} í¬ë¡¤ë§ ì‹œì‘")
            logger.info("=" * 80)
            
            # í¬ë¡¤ëŸ¬ ìƒì„±
            crawler = NaverMapDistrictCrawler(
                district_name=district_name,
                headless=headless_mode
            )
            
            # í•´ë‹¹ êµ¬ì˜ API ë°ì´í„°ë¡œ í¬ë¡¤ë§ ì‹œì‘
            await crawler.crawl_district_api(delay=delay_seconds)
            
            logger.info("")
            logger.info("=" * 80)
            logger.info(f"[{idx}/{len(districts_to_crawl)}] {district_name} í¬ë¡¤ë§ ì™„ë£Œ!")
            logger.info("=" * 80)
            
            # ë‹¤ìŒ êµ¬ë¡œ ë„˜ì–´ê°€ê¸° ì „ ëŒ€ê¸° (ë§ˆì§€ë§‰ êµ¬ê°€ ì•„ë‹Œ ê²½ìš°)
            if idx < len(districts_to_crawl):
                wait_time = 60  # êµ¬ ì‚¬ì´ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
                logger.info(f"ë‹¤ìŒ êµ¬ í¬ë¡¤ë§ ì „ {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘...")
                await asyncio.sleep(wait_time)
                
        except Exception as e:
            logger.error(f"âœ— {district_name} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë‹¤ìŒ êµ¬ ì§„í–‰ ì—¬ë¶€ í™•ì¸
            if idx < len(districts_to_crawl):
                logger.info(f"ë‹¤ìŒ êµ¬({districts_to_crawl[idx]})ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
                await asyncio.sleep(30)
    
    logger.info("")
    logger.info("=" * 80)
    logger.info("ğŸ‰ ëª¨ë“  êµ¬ í¬ë¡¤ë§ ì™„ë£Œ!")
    logger.info("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())